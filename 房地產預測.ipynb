{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57c69326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>sector</th>\n",
       "      <th>year</th>\n",
       "      <th>amount_new_house_transactions</th>\n",
       "      <th>year_end_registered_population_10k</th>\n",
       "      <th>total_households_10k</th>\n",
       "      <th>year_end_resident_population_10k</th>\n",
       "      <th>year_end_total_employed_population_10k</th>\n",
       "      <th>year_end_urban_non_private_employees_10k</th>\n",
       "      <th>private_individual_and_other_employees_10k</th>\n",
       "      <th>...</th>\n",
       "      <th>medical_health_rehabilitation_institution_dense</th>\n",
       "      <th>medical_health_first_aid_center_dense</th>\n",
       "      <th>medical_health_blood_donation_station_dense</th>\n",
       "      <th>medical_health_disease_prevention_institution_dense</th>\n",
       "      <th>medical_health_general_hospital_dense</th>\n",
       "      <th>medical_health_clinic_dense</th>\n",
       "      <th>education_training_school_education_middle_school_dense</th>\n",
       "      <th>education_training_school_education_primary_school_dense</th>\n",
       "      <th>education_training_school_education_kindergarten_dense</th>\n",
       "      <th>education_training_school_education_research_institution_dense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>sector 1</td>\n",
       "      <td>2019</td>\n",
       "      <td>13827.14</td>\n",
       "      <td>953.72</td>\n",
       "      <td>313.8455</td>\n",
       "      <td>1530.59</td>\n",
       "      <td>1125.89</td>\n",
       "      <td>400.22</td>\n",
       "      <td>725.672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.600000e-07</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>sector 1</td>\n",
       "      <td>2019</td>\n",
       "      <td>13827.14</td>\n",
       "      <td>953.72</td>\n",
       "      <td>313.8455</td>\n",
       "      <td>1530.59</td>\n",
       "      <td>1125.89</td>\n",
       "      <td>400.22</td>\n",
       "      <td>725.672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.600000e-07</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>sector 1</td>\n",
       "      <td>2019</td>\n",
       "      <td>13827.14</td>\n",
       "      <td>953.72</td>\n",
       "      <td>313.8455</td>\n",
       "      <td>1530.59</td>\n",
       "      <td>1125.89</td>\n",
       "      <td>400.22</td>\n",
       "      <td>725.672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.600000e-07</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>sector 1</td>\n",
       "      <td>2019</td>\n",
       "      <td>13827.14</td>\n",
       "      <td>953.72</td>\n",
       "      <td>313.8455</td>\n",
       "      <td>1530.59</td>\n",
       "      <td>1125.89</td>\n",
       "      <td>400.22</td>\n",
       "      <td>725.672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.600000e-07</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>sector 1</td>\n",
       "      <td>2019</td>\n",
       "      <td>13827.14</td>\n",
       "      <td>953.72</td>\n",
       "      <td>313.8455</td>\n",
       "      <td>1530.59</td>\n",
       "      <td>1125.89</td>\n",
       "      <td>400.22</td>\n",
       "      <td>725.672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.600000e-07</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        month    sector  year  amount_new_house_transactions  \\\n",
       "0  2019-01-01  sector 1  2019                       13827.14   \n",
       "1  2019-01-01  sector 1  2019                       13827.14   \n",
       "2  2019-01-01  sector 1  2019                       13827.14   \n",
       "3  2019-01-01  sector 1  2019                       13827.14   \n",
       "4  2019-01-01  sector 1  2019                       13827.14   \n",
       "\n",
       "   year_end_registered_population_10k  total_households_10k  \\\n",
       "0                              953.72              313.8455   \n",
       "1                              953.72              313.8455   \n",
       "2                              953.72              313.8455   \n",
       "3                              953.72              313.8455   \n",
       "4                              953.72              313.8455   \n",
       "\n",
       "   year_end_resident_population_10k  year_end_total_employed_population_10k  \\\n",
       "0                           1530.59                                 1125.89   \n",
       "1                           1530.59                                 1125.89   \n",
       "2                           1530.59                                 1125.89   \n",
       "3                           1530.59                                 1125.89   \n",
       "4                           1530.59                                 1125.89   \n",
       "\n",
       "   year_end_urban_non_private_employees_10k  \\\n",
       "0                                    400.22   \n",
       "1                                    400.22   \n",
       "2                                    400.22   \n",
       "3                                    400.22   \n",
       "4                                    400.22   \n",
       "\n",
       "   private_individual_and_other_employees_10k  ...  \\\n",
       "0                                     725.672  ...   \n",
       "1                                     725.672  ...   \n",
       "2                                     725.672  ...   \n",
       "3                                     725.672  ...   \n",
       "4                                     725.672  ...   \n",
       "\n",
       "   medical_health_rehabilitation_institution_dense  \\\n",
       "0                                         0.000113   \n",
       "1                                         0.000113   \n",
       "2                                         0.000113   \n",
       "3                                         0.000113   \n",
       "4                                         0.000113   \n",
       "\n",
       "   medical_health_first_aid_center_dense  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "   medical_health_blood_donation_station_dense  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   medical_health_disease_prevention_institution_dense  \\\n",
       "0                                       8.600000e-07     \n",
       "1                                       8.600000e-07     \n",
       "2                                       8.600000e-07     \n",
       "3                                       8.600000e-07     \n",
       "4                                       8.600000e-07     \n",
       "\n",
       "   medical_health_general_hospital_dense  medical_health_clinic_dense  \\\n",
       "0                               0.000041                     0.000038   \n",
       "1                               0.000041                     0.000038   \n",
       "2                               0.000041                     0.000038   \n",
       "3                               0.000041                     0.000038   \n",
       "4                               0.000041                     0.000038   \n",
       "\n",
       "   education_training_school_education_middle_school_dense  \\\n",
       "0                                           0.000016         \n",
       "1                                           0.000016         \n",
       "2                                           0.000016         \n",
       "3                                           0.000016         \n",
       "4                                           0.000016         \n",
       "\n",
       "   education_training_school_education_primary_school_dense  \\\n",
       "0                                           0.000028          \n",
       "1                                           0.000028          \n",
       "2                                           0.000028          \n",
       "3                                           0.000028          \n",
       "4                                           0.000028          \n",
       "\n",
       "   education_training_school_education_kindergarten_dense  \\\n",
       "0                                           0.000063        \n",
       "1                                           0.000063        \n",
       "2                                           0.000063        \n",
       "3                                           0.000063        \n",
       "4                                           0.000063        \n",
       "\n",
       "   education_training_school_education_research_institution_dense  \n",
       "0                                           0.000014               \n",
       "1                                           0.000014               \n",
       "2                                           0.000014               \n",
       "3                                           0.000014               \n",
       "4                                           0.000014               \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('merged_training_table.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a04c1af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非數值欄位: ['month', 'sector', 'keyword', 'source']\n"
     ]
    }
   ],
   "source": [
    "X=df.drop('amount_new_house_transactions',axis=1)\n",
    "y=df['amount_new_house_transactions']\n",
    "\n",
    "non_numeric = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "print(\"非數值欄位:\", non_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f6ac0225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b069cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = pd.to_datetime(df['month'])\n",
    "df['year'] = df['year'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aaa74e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非數值欄位: ['month', 'sector', 'year', 'keyword', 'source']\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('amount_new_house_transactions', axis=1)  # 轉型後再建\n",
    "non_numeric = X.select_dtypes(exclude=['number']).columns.tolist()\n",
    "print(\"非數值欄位:\", non_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4868a3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0618068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\user\\anaconda3\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d4e347fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear:CV (Kaggle two-stage score) mean: 0.0\n",
      "Linear:Each split: [0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF:CV (Kaggle two-stage score) mean: 0.0\n",
      "RF:Each split: [0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['total_fixed_asset_investment_10k']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB:CV (Kaggle two-stage score) mean: 0.0\n",
      "XGB:Each split: [0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\71088798.py:85: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.abs(y_pred - y_true) / np.abs(y_true)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit , cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "num_cols=X.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols=X.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "pre_linear=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',Pipeline([\n",
    "            ('imputer',SimpleImputer(strategy='median')),\n",
    "            ('scaler',StandardScaler())\n",
    "        ]),num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pre_tree=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',Pipeline([\n",
    "            ('imputer',SimpleImputer(strategy='median')),\n",
    "        ]),num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "linear=LinearRegression()\n",
    "pipe_linear=Pipeline([\n",
    "    ('pre_linear',pre_linear),\n",
    "    ('linear',linear),\n",
    "])\n",
    "\n",
    "rf=RandomForestRegressor(\n",
    "    n_estimators=100,        \n",
    "    max_depth=12,            \n",
    "    min_samples_split=20,    \n",
    "    min_samples_leaf=5,      \n",
    "    max_features='sqrt',   \n",
    "    bootstrap=True,          \n",
    "    max_samples=0.7,         \n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "pipe_rf=Pipeline([\n",
    "    ('pre_rf',pre_tree),\n",
    "    ('rf',rf),\n",
    "])\n",
    "\n",
    "xgb=XGBRegressor(\n",
    "    n_estimators=200,        \n",
    "    max_depth=6,             \n",
    "    learning_rate=0.1,      \n",
    "    subsample=0.8,           \n",
    "    colsample_bytree=0.8,    \n",
    "    min_child_weight=5,      \n",
    "    reg_lambda=1.0,          \n",
    "    n_jobs=-1,              \n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"            \n",
    ")\n",
    "pipe_xgb=Pipeline([\n",
    "    ('pre_xgb',pre_tree),\n",
    "    ('xgb',xgb),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#設定評分方法\n",
    "# —— 兩階段 MAPE：回傳「分數，越大越好」——\n",
    "def two_stage_mape_score(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    # APE：處理 y_true=0 的情況（與常識一致：真值為 0 且預測也為 0 → 0；否則 → inf）\n",
    "    ape = np.where(\n",
    "        y_true == 0,\n",
    "        np.where(np.isclose(y_pred, 0.0), 0.0, np.inf),\n",
    "        np.abs(y_pred - y_true) / np.abs(y_true)\n",
    "    )\n",
    "\n",
    "    n = len(ape)\n",
    "    frac_big = np.mean(ape > 1)  # >100% 的比例\n",
    "\n",
    "    # 第一階段：若 >30% 的樣本 APE>1 → 直接 0 分\n",
    "    if frac_big > 0.3:\n",
    "        return 0.0\n",
    "\n",
    "    # 第二階段：只用 APE<=1 的樣本，計算縮放後的 MAPE，score = 1 - scaled_mape\n",
    "    mask_ok = (ape <= 1) & np.isfinite(ape)\n",
    "    if mask_ok.sum() == 0:\n",
    "        return 0.0  # 理論上不會到這裡，保險起見\n",
    "\n",
    "    mape_ok = ape[mask_ok].mean()\n",
    "    frac_ok = mask_ok.sum() / n\n",
    "    scaled_mape = mape_ok / frac_ok\n",
    "    score = 1.0 - scaled_mape\n",
    "\n",
    "    # 分數界於 [0,1]（理論上已是如此，這裡穩健處理）\n",
    "    return float(np.clip(score, 0.0, 1.0))\n",
    "\n",
    "# 包成 sklearn scorer（越大越好）\n",
    "kaggle_scorer = make_scorer(two_stage_mape_score, greater_is_better=True)\n",
    "\n",
    "\n",
    "tscv=TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "cv_scores_linear=cross_val_score(\n",
    "    pipe_linear,X[num_cols],y,cv=tscv,scoring=kaggle_scorer\n",
    ")\n",
    "print(\"Linear:CV (Kaggle two-stage score) mean:\", cv_scores_linear.mean())\n",
    "print(\"Linear:Each split:\", cv_scores_linear)\n",
    "\n",
    "cv_scores_rf=cross_val_score(\n",
    "    pipe_rf,X[num_cols],y,cv=tscv,scoring=kaggle_scorer\n",
    ")\n",
    "print(\"RF:CV (Kaggle two-stage score) mean:\", cv_scores_rf.mean())\n",
    "print(\"RF:Each split:\", cv_scores_rf)\n",
    "\n",
    "cv_scores_xgb=cross_val_score(\n",
    "    pipe_xgb,X[num_cols],y,cv=tscv,scoring=kaggle_scorer\n",
    ")\n",
    "print(\"XGB:CV (Kaggle two-stage score) mean:\", cv_scores_xgb.mean())\n",
    "print(\"XGB:Each split:\", cv_scores_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "356d6e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要丟掉的欄位數: 13\n"
     ]
    }
   ],
   "source": [
    "# 1. 全 NaN\n",
    "nan_cols = X.columns[X.isna().all()]\n",
    "\n",
    "# 2. 幾乎全 NaN（例如超過 95% 缺失）\n",
    "mostly_nan_cols = X.columns[X.isna().mean() > 0.95]\n",
    "\n",
    "# 3. 常數或接近常數欄\n",
    "const_cols = X.columns[X.nunique(dropna=True) <= 1]\n",
    "\n",
    "# 設定一個閾值，例如：非 NaN 比例 < 5% 就刪掉\n",
    "low_info_cols = X.columns[(X.notna().mean() < 0.05)]\n",
    "\n",
    "drop_cols = nan_cols.union(mostly_nan_cols).union(const_cols).union(low_info_cols)\n",
    "print(\"要丟掉的欄位數:\", len(drop_cols))\n",
    "\n",
    "X=X.drop(columns=drop_cols)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8aedd288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y==0 數量: 65160 / 450300\n"
     ]
    }
   ],
   "source": [
    "print(\"y==0 數量:\", (y == 0).sum(), \"/\", len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e15db682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear:CV (Kaggle two-stage score) mean: 0.0\n",
      "Linear:Each split: [0. 0. 0. 0. 0.]\n",
      "RF:CV (Kaggle two-stage score) mean: 0.0\n",
      "RF:Each split: [0. 0. 0. 0. 0.]\n",
      "XGB:CV (Kaggle two-stage score) mean: 0.0\n",
      "XGB:Each split: [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# ===== 修正版兩階段 MAPE (處理 y_true=0) =====\n",
    "def two_stage_mape_score(y_true, y_pred, epsilon=1e-6):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    # 避免除以零：分母加 epsilon\n",
    "    ape = np.abs(y_pred - y_true) / np.maximum(np.abs(y_true), epsilon)\n",
    "\n",
    "    n = len(ape)\n",
    "    frac_big = np.mean(ape > 1)  # >100% 的比例\n",
    "\n",
    "    # 第一階段：若超過 30% 的樣本 APE > 1 → 直接 0 分\n",
    "    if frac_big > 0.3:\n",
    "        return 0.0\n",
    "\n",
    "    # 第二階段：只算 APE <= 1 的樣本\n",
    "    mask_ok = (ape <= 1) & np.isfinite(ape)\n",
    "    if mask_ok.sum() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    mape_ok = ape[mask_ok].mean()\n",
    "    frac_ok = mask_ok.sum() / n\n",
    "    scaled_mape = mape_ok / frac_ok\n",
    "    score = 1.0 - scaled_mape\n",
    "\n",
    "    return float(np.clip(score, 0.0, 1.0))\n",
    "\n",
    "# ===== 包成 sklearn scorer (越大越好) =====\n",
    "kaggle_scorer = make_scorer(two_stage_mape_score, greater_is_better=True)\n",
    "\n",
    "\n",
    "num_cols=X.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols=X.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "pre_linear=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',Pipeline([\n",
    "            ('imputer',SimpleImputer(strategy='median')),\n",
    "            ('scaler',StandardScaler())\n",
    "        ]),num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pre_tree=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',Pipeline([\n",
    "            ('imputer',SimpleImputer(strategy='median')),\n",
    "        ]),num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "linear=LinearRegression()\n",
    "pipe_linear=Pipeline([\n",
    "    ('pre_linear',pre_linear),\n",
    "    ('linear',linear),\n",
    "])\n",
    "\n",
    "rf=RandomForestRegressor(\n",
    "    n_estimators=100,        \n",
    "    max_depth=12,            \n",
    "    min_samples_split=20,    \n",
    "    min_samples_leaf=5,      \n",
    "    max_features='sqrt',   \n",
    "    bootstrap=True,          \n",
    "    max_samples=0.7,         \n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "pipe_rf=Pipeline([\n",
    "    ('pre_rf',pre_tree),\n",
    "    ('rf',rf),\n",
    "])\n",
    "\n",
    "xgb=XGBRegressor(\n",
    "    n_estimators=200,        \n",
    "    max_depth=6,             \n",
    "    learning_rate=0.1,      \n",
    "    subsample=0.8,           \n",
    "    colsample_bytree=0.8,    \n",
    "    min_child_weight=5,      \n",
    "    reg_lambda=1.0,          \n",
    "    n_jobs=-1,              \n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"        \n",
    ")\n",
    "pipe_xgb=Pipeline([\n",
    "    ('pre_xgb',pre_tree),\n",
    "    ('xgb',xgb),\n",
    "])\n",
    "\n",
    "tscv=TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "cv_scores_linear=cross_val_score(\n",
    "    pipe_linear,X[num_cols],y,cv=tscv,scoring=kaggle_scorer\n",
    ")\n",
    "print(\"Linear:CV (Kaggle two-stage score) mean:\", cv_scores_linear.mean())\n",
    "print(\"Linear:Each split:\", cv_scores_linear)\n",
    "\n",
    "cv_scores_rf=cross_val_score(\n",
    "    pipe_rf,X[num_cols],y,cv=tscv,scoring=kaggle_scorer\n",
    ")\n",
    "print(\"RF:CV (Kaggle two-stage score) mean:\", cv_scores_rf.mean())\n",
    "print(\"RF:Each split:\", cv_scores_rf)\n",
    "\n",
    "cv_scores_xgb=cross_val_score(\n",
    "    pipe_xgb,X[num_cols],y,cv=tscv,scoring=kaggle_scorer\n",
    ")\n",
    "print(\"XGB:CV (Kaggle two-stage score) mean:\", cv_scores_xgb.mean())\n",
    "print(\"XGB:Each split:\", cv_scores_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "37605d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各折 >100% 比例： [0.22371752165223185, 0.34900732844770155, 0.37534976682211857, 0.31491005996002663, 0.3866222518321119] 平均： 0.32992138574283814\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# 假設：X(含 month, sector, y_col)、features、pipeline 都已經準備好\n",
    "\n",
    "def frac_big_ape(y_true, y_pred, eps=1e-6):\n",
    "    ape = np.abs(y_pred - y_true) / np.maximum(np.abs(y_true), eps)\n",
    "    return float((ape > 1).mean())\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "ratios = []\n",
    "for tr_idx, te_idx in tscv.split(X):\n",
    "    Xtr, Xte = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    ytr, yte = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "    mdl = pipe_linear.fit(Xtr[num_cols], ytr)\n",
    "    pred = mdl.predict(Xte[num_cols])\n",
    "    pred = np.clip(pred, 0.0, None)  # y≥0\n",
    "    ratios.append(frac_big_ape(yte.values, pred))\n",
    "\n",
    "print(\"各折 >100% 比例：\", ratios, \"平均：\", np.mean(ratios))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2d19d2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各折 >100% 比例： [0.3487008660892738, 0.40924716855429716, 0.33557628247834775, 0.45169886742171883, 0.4340972684876749] 平均： 0.3958640906062625\n"
     ]
    }
   ],
   "source": [
    "def frac_big_ape(y_true, y_pred, eps=1e-6):\n",
    "    ape = np.abs(y_pred - y_true) / np.maximum(np.abs(y_true), eps)\n",
    "    return float((ape > 1).mean())\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "ratios = []\n",
    "for tr_idx, te_idx in tscv.split(X):\n",
    "    Xtr, Xte = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    ytr, yte = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "    mdl = pipe_rf.fit(Xtr[num_cols], ytr)\n",
    "    pred = mdl.predict(Xte[num_cols])\n",
    "    pred = np.clip(pred, 0.0, None)  # y≥0\n",
    "    ratios.append(frac_big_ape(yte.values, pred))\n",
    "\n",
    "print(\"各折 >100% 比例：\", ratios, \"平均：\", np.mean(ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0fcdfbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各折 >100% 比例： [0.4108061292471685, 0.34739506995336444, 0.3012658227848101, 0.39949367088607596, 0.3853431045969354] 平均： 0.36886075949367086\n"
     ]
    }
   ],
   "source": [
    "def frac_big_ape(y_true, y_pred, eps=1e-6):\n",
    "    ape = np.abs(y_pred - y_true) / np.maximum(np.abs(y_true), eps)\n",
    "    return float((ape > 1).mean())\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "ratios = []\n",
    "for tr_idx, te_idx in tscv.split(X):\n",
    "    Xtr, Xte = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    ytr, yte = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "    mdl = pipe_xgb.fit(Xtr[num_cols], ytr)\n",
    "    pred = mdl.predict(Xte[num_cols])\n",
    "    pred = np.clip(pred, 0.0, None)  # y≥0\n",
    "    ratios.append(frac_big_ape(yte.values, pred))\n",
    "\n",
    "print(\"各折 >100% 比例：\", ratios, \"平均：\", np.mean(ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a2e34ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy:CV (Kaggle two-stage score) mean: 0.0\n",
      "Dummy:Each split: [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_reg=DummyRegressor(strategy='median')\n",
    "pipe_dummy_reg=Pipeline([\n",
    "    ('pre_dummy_reg',pre_tree),\n",
    "    ('dummy_reg',dummy_reg),\n",
    "])\n",
    "cv_scores_dummy_ref=cross_val_score(\n",
    "    pipe_dummy_reg,X[num_cols],y,cv=tscv,scoring=kaggle_scorer\n",
    ")\n",
    "print(\"Dummy:CV (Kaggle two-stage score) mean:\", cv_scores_dummy_ref.mean())\n",
    "print(\"Dummy:Each split:\", cv_scores_dummy_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "52c35895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year_month\"] = pd.to_datetime(df[\"month\"]).dt.to_period(\"M\").dt.to_timestamp()\n",
    "df = df.sort_values([\"sector\", \"year_month\"]).reset_index(drop=True)\n",
    "\n",
    "X = df.drop(\"amount_new_house_transactions\", axis=1)\n",
    "y = df[\"amount_new_house_transactions\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "23dffb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  baseline  two_stage_score  frac_APE>100%\n",
      "0     lag1         0.995663       0.002385\n",
      "2      ma3         0.989868       0.005241\n",
      "3      ma6         0.981318       0.009460\n",
      "1    lag12         0.945110       0.028621\n"
     ]
    }
   ],
   "source": [
    "date_col  = \"year_month\"   \n",
    "group_col = \"sector\"\n",
    "\n",
    "g = df.groupby(group_col)[\"amount_new_house_transactions\"]\n",
    "\n",
    "\n",
    "#建立天真基線\n",
    "preds = {\n",
    "    \"lag1\":  g.shift(1),\n",
    "    \"lag12\": g.shift(12),\n",
    "    \"ma3\":   g.shift(1).rolling(3).mean(),\n",
    "    \"ma6\":   g.shift(1).rolling(6).mean(),\n",
    "}\n",
    "\n",
    "#評估\n",
    "rows = []\n",
    "y_true = y.to_numpy(float)\n",
    "for name, p in preds.items():\n",
    "    y_pred = np.where(np.isnan(p), 0.0, p)  # 前幾期沒有歷史 → 補0\n",
    "    y_pred = np.clip(y_pred, 0.0, None)     # y≥0\n",
    "    score  = two_stage_mape_score(y_true, y_pred)\n",
    "    ratio  = frac_big_ape(y_true, y_pred)\n",
    "    rows.append((name, score, ratio))\n",
    "\n",
    "print(pd.DataFrame(rows, columns=[\"baseline\",\"two_stage_score\",\"frac_APE>100%\"])\n",
    "        .sort_values(\"two_stage_score\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "97480b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#刪除NaN值的X欄\n",
    "# 1. 全 NaN\n",
    "nan_cols = df.columns[df.isna().all()]\n",
    "\n",
    "# 2. 幾乎全 NaN（例如超過 95% 缺失）\n",
    "mostly_nan_cols = df.columns[df.isna().mean() > 0.95]\n",
    "\n",
    "# 3. 常數或接近常數欄\n",
    "const_cols = df.columns[df.nunique(dropna=True) <= 1]\n",
    "\n",
    "# 設定一個閾值，例如：非 NaN 比例 < 5% 就刪掉\n",
    "low_info_cols = df.columns[(df.notna().mean() < 0.05)]\n",
    "\n",
    "drop_cols = nan_cols.union(mostly_nan_cols).union(const_cols).union(low_info_cols)\n",
    "\n",
    "df=df.drop(columns=drop_cols)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ab015bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear CV mean: 0.8909493073294396\n",
      "linear CV each split: [0.95472145 0.91389829 0.8880529  0.82902952 0.86904438]\n",
      "RF CV mean: 0.2934185613385213\n",
      "RF CV each split: [0.72686491 0.         0.74022789 0.         0.        ]\n",
      "XGB CV mean: 0.8964605311574093\n",
      "XGB CV each split: [0.86925971 0.86879327 0.93166086 0.89678574 0.91580307]\n"
     ]
    }
   ],
   "source": [
    "# === 安裝工具包 ===\n",
    "from lag_rolling_tools import GroupTimeLagRoller\n",
    "\n",
    "# === 定義欄位 ===\n",
    "date_col  = \"year_month\"\n",
    "group_col = \"sector\"\n",
    "y_col     = [\"amount_new_house_transactions\"]\n",
    "\n",
    "cat_cols = ['month', 'sector', 'year', 'keyword', 'source']\n",
    "\n",
    "# 數值欄位: 自動選 numeric & 排除掉 y, group, date\n",
    "exclude = set(cat_cols + y_col + [date_col, group_col])\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in exclude]\n",
    "\n",
    "# === Lag 特徵生成器 ===\n",
    "lagrolls = GroupTimeLagRoller(\n",
    "    group_key=group_col,\n",
    "    time_col=date_col,\n",
    "    cols=y_col,\n",
    "    lags=[1, 3, 12],\n",
    "    roll_windows=[3, 6],\n",
    "    roll_funcs=['mean'],\n",
    "    shift_for_rolling=1,\n",
    "    drop_original_y=True,\n",
    ")\n",
    "\n",
    "lag_cols = lagrolls.get_column_names()\n",
    "\n",
    "# === Column Selector: 排除 lag 用來 impute ===\n",
    "def select_num_excl_lag(X):\n",
    "    numeric = X.select_dtypes(include=[np.number]).columns\n",
    "    return [c for c in numeric if c not in set(lag_cols)]\n",
    "\n",
    "# === ColumnTransformer ===\n",
    "pre_linear=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',Pipeline([\n",
    "            ('imputer',SimpleImputer(strategy='median')),\n",
    "            ('scaler',StandardScaler())\n",
    "        ]),select_num_excl_lag),\n",
    "        ('lag',SimpleImputer(strategy='constant',fill_value=0),lag_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pre_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median'))\n",
    "        ]), select_num_excl_lag),\n",
    "        ('lag',SimpleImputer(strategy='constant',fill_value=0),lag_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# === Pipeline ===\n",
    "pipe_linear_lag=Pipeline([\n",
    "    ('lagrolls',lagrolls),\n",
    "    ('pre',pre_linear),\n",
    "    ('linear',linear)\n",
    "])\n",
    "\n",
    "pipe_rf_lag=Pipeline([\n",
    "    ('lagrolls',lagrolls),\n",
    "    ('pre',pre_tree),\n",
    "    ('rf',rf)\n",
    "])\n",
    "\n",
    "pipe_xgb_lag = Pipeline([\n",
    "    ('lagrolls', lagrolls),\n",
    "    ('pre', pre_tree),\n",
    "    ('xgb', xgb)   \n",
    "])\n",
    "\n",
    "# === Cross Validation ===\n",
    "X = df\n",
    "y = df[y_col[0]]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "cv_scores_linear=cross_val_score(pipe_linear_lag,X=X,y=y,cv=tscv,scoring=kaggle_scorer)\n",
    "print(\"linear CV mean:\", cv_scores_linear.mean())\n",
    "print(\"linear CV each split:\", cv_scores_linear)\n",
    "\n",
    "cv_scores_rf=cross_val_score(pipe_rf_lag,X=X,y=y,cv=tscv,scoring=kaggle_scorer)\n",
    "print(\"RF CV mean:\", cv_scores_rf.mean())\n",
    "print(\"RF CV each split:\", cv_scores_rf)\n",
    "\n",
    "cv_scores_xgb = cross_val_score(pipe_xgb_lag, X=X, y=y, cv=tscv, scoring=kaggle_scorer)\n",
    "\n",
    "print(\"XGB CV mean:\", cv_scores_xgb.mean())\n",
    "print(\"XGB CV each split:\", cv_scores_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "710f9947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0d8dfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear CV mean: 0.8909808407714385\n",
      "linear CV each split: [0.9540819  0.91451592 0.89341048 0.82454542 0.8683505 ]\n",
      "RF CV mean: 0.30201793995685555\n",
      "RF CV each split: [0.74679763 0.         0.76329207 0.         0.        ]\n",
      "XGB CV mean: 0.8864154058832513\n",
      "XGB CV each split: [0.87536771 0.81959113 0.92981984 0.89693062 0.91036774]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn import FunctionSampler\n",
    "# === 定義欄位 ===\n",
    "date_col  = \"year_month\"\n",
    "group_col = \"sector\"\n",
    "y_col     = [\"amount_new_house_transactions\"]\n",
    "\n",
    "cat_cols = ['month', 'sector', 'year', 'keyword', 'source']\n",
    "\n",
    "# 數值欄位: 自動選 numeric & 排除掉 y, group, date\n",
    "exclude = set(cat_cols + y_col + [date_col, group_col])\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in exclude]\n",
    "\n",
    "# === Lag 特徵生成器 ===\n",
    "lagrolls = GroupTimeLagRoller(\n",
    "    group_key=group_col,\n",
    "    time_col=date_col,\n",
    "    cols=y_col,\n",
    "    lags=[1, 3, 12],\n",
    "    roll_windows=[3, 6],\n",
    "    roll_funcs=['mean'],\n",
    "    shift_for_rolling=1,\n",
    "    drop_original_y=True,\n",
    ")\n",
    "\n",
    "lag_cols = lagrolls.get_column_names()\n",
    "\n",
    "# 2) 刪暖機段：在 lag 後、pre_tree 前，同步處理 X 與 y\n",
    "def drop_warmup_rows(X, y, lag_columns):\n",
    "    # X 此時是 DataFrame（因為前一步是你自訂的 transformer）\n",
    "    mask = X[lag_columns].notna().all(axis=1)\n",
    "    # 同步篩 X 與 y（保留 index 對齊）\n",
    "    return X.loc[mask], y.loc[mask]\n",
    "\n",
    "dropper = FunctionSampler(\n",
    "    func=drop_warmup_rows,\n",
    "    kw_args={'lag_columns': lag_cols},\n",
    "    validate=False   # ← 關鍵：不要把 y 當分類標籤檢查\n",
    ")\n",
    "\n",
    "# === Column Selector: 排除 lag 用來 impute ===\n",
    "def select_num_excl_lag(X):\n",
    "    numeric = X.select_dtypes(include=[np.number]).columns\n",
    "    return [c for c in numeric if c not in set(lag_cols)]\n",
    "\n",
    "# === ColumnTransformer ===\n",
    "pre_linear=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',Pipeline([\n",
    "            ('imputer',SimpleImputer(strategy='median')),\n",
    "            ('scaler',StandardScaler())\n",
    "        ]),select_num_excl_lag),\n",
    "        ('lag', SimpleImputer(strategy='constant',fill_value=0), lag_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "pre_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median'))\n",
    "        ]), select_num_excl_lag),\n",
    "        ('lag', 'passthrough', lag_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n",
    "# === Pipeline ===\n",
    "pipe_linear_lag=ImbPipeline([\n",
    "    ('lagrolls',lagrolls),\n",
    "    ('dropper',dropper),\n",
    "    ('pre',pre_linear),\n",
    "    ('linear',linear)\n",
    "])\n",
    "\n",
    "pipe_rf_lag=ImbPipeline([\n",
    "    ('lagrolls',lagrolls),\n",
    "    ('dropper',dropper),\n",
    "    ('pre',pre_tree),\n",
    "    ('rf',rf)\n",
    "])\n",
    "\n",
    "pipe_xgb_lag = ImbPipeline([\n",
    "    ('lagrolls', lagrolls),\n",
    "    ('dropper',dropper),\n",
    "    ('pre', pre_tree),\n",
    "    ('xgb', xgb)   # 這裡放你的 XGBRegressor\n",
    "])\n",
    "\n",
    "# === Cross Validation ===\n",
    "X = df\n",
    "y = df[y_col[0]]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_scores_linear=cross_val_score(pipe_linear_lag,X=X,y=y,cv=tscv,scoring=kaggle_scorer)\n",
    "print(\"linear CV mean:\", cv_scores_linear.mean())\n",
    "print(\"linear CV each split:\", cv_scores_linear)\n",
    "\n",
    "cv_scores_rf=cross_val_score(pipe_rf_lag,X=X,y=y,cv=tscv,scoring=kaggle_scorer)\n",
    "print(\"RF CV mean:\", cv_scores_rf.mean())\n",
    "print(\"RF CV each split:\", cv_scores_rf)\n",
    "\n",
    "cv_scores_xgb = cross_val_score(pipe_xgb_lag, X=X, y=y, cv=tscv, scoring=kaggle_scorer)\n",
    "\n",
    "print(\"XGB CV mean:\", cv_scores_xgb.mean())\n",
    "print(\"XGB CV each split:\", cv_scores_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6d674b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB CV mean: 0.8964605311574093\n",
      "XGB CV each split: [0.86925971 0.86879327 0.93166086 0.89678574 0.91580307]\n"
     ]
    }
   ],
   "source": [
    "# 確認XGB，NaN補0為baseline\n",
    "\n",
    "\n",
    "# === 定義欄位 ===\n",
    "date_col  = \"year_month\"\n",
    "group_col = \"sector\"\n",
    "y_col     = [\"amount_new_house_transactions\"]\n",
    "\n",
    "cat_cols = ['month', 'sector', 'year', 'keyword', 'source']\n",
    "\n",
    "# 數值欄位: 自動選 numeric & 排除掉 y, group, date\n",
    "exclude = set(cat_cols + y_col + [date_col, group_col])\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in exclude]\n",
    "\n",
    "# === Lag 特徵生成器 ===\n",
    "lagrolls = GroupTimeLagRoller(\n",
    "    group_key=group_col,\n",
    "    time_col=date_col,\n",
    "    cols=y_col,\n",
    "    lags=[1, 3, 12],\n",
    "    roll_windows=[3, 6],\n",
    "    roll_funcs=['mean'],\n",
    "    shift_for_rolling=1,\n",
    "    drop_original_y=True,\n",
    ")\n",
    "\n",
    "lag_cols = lagrolls.get_column_names()\n",
    "\n",
    "# === Column Selector: 排除 lag 用來 impute ===\n",
    "def select_num_excl_lag(X):\n",
    "    numeric = X.select_dtypes(include=[np.number]).columns\n",
    "    return [c for c in numeric if c not in set(lag_cols)]\n",
    "\n",
    "# === ColumnTransformer ===\n",
    "pre_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median'))\n",
    "        ]), select_num_excl_lag),\n",
    "        ('lag',SimpleImputer(strategy='constant',fill_value=0),lag_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# === Pipeline ===\n",
    "pipe_xgb_lag = Pipeline([\n",
    "    ('lagrolls', lagrolls),\n",
    "    ('pre', pre_tree),\n",
    "    ('xgb', xgb)   \n",
    "])\n",
    "\n",
    "# === Cross Validation ===\n",
    "X = df\n",
    "y = df[y_col[0]]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "cv_scores_xgb = cross_val_score(pipe_xgb_lag, X=X, y=y, cv=tscv, scoring=kaggle_scorer)\n",
    "\n",
    "print(\"XGB CV mean:\", cv_scores_xgb.mean())\n",
    "print(\"XGB CV each split:\", cv_scores_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "408b5860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag__amount_new_house_transactions_lag1                          0.584319\n",
      "lag__amount_new_house_transactions_rollmean3_s1_mp3              0.075728\n",
      "lag__amount_new_house_transactions_rollmean6_s1_mp6              0.074697\n",
      "num__education_training_school_education_research_institution    0.030558\n",
      "num__surrounding_housing_average_price                           0.027720\n",
      "num__num_pre_owned_house_transactions_nearby_sectors             0.017504\n",
      "num__price_pre_owned_house_transactions                          0.016917\n",
      "num__surrounding_shop_average_rent                               0.016227\n",
      "num__area_pre_owned_house_transactions_nearby_sectors            0.015392\n",
      "num__price_new_house_transactions_nearby_sectors                 0.010232\n",
      "num__price_pre_owned_house_transactions_nearby_sectors           0.009477\n",
      "num__office_population                                           0.008139\n",
      "num__period_new_house_sell_through_nearby_sectors                0.007307\n",
      "num__area_per_unit_new_house_transactions_nearby_sectors         0.006726\n",
      "num__area_pre_owned_house_transactions                           0.006108\n",
      "num__tertiary_industry_percent                                   0.004284\n",
      "num__amount_pre_owned_house_transactions_nearby_sectors          0.003380\n",
      "num__number_of_office_building_commercial                        0.002923\n",
      "num__medical_health_pharmaceutical_healthcare                    0.002731\n",
      "num__unranked_malls_dense                                        0.002705\n",
      "num__num_land_transactions_nearby_sectors                        0.002614\n",
      "num__amount_new_house_transactions_nearby_sectors                0.002351\n",
      "num__residential_commercial_dense                                0.002248\n",
      "num__resident_population                                         0.002192\n",
      "num__jewelry_stores_dense                                        0.002157\n",
      "num__area_new_house_available_for_sale_nearby_sectors            0.002010\n",
      "num__sector_coverage                                             0.001937\n",
      "num__catering_food_stores_dense                                  0.001763\n",
      "num__total_households_10k                                        0.001753\n",
      "num__resident_registered_ratio                                   0.001693\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# === 1) 先把管線 fit 一次（可用整體或你切好的 train）===\n",
    "pipe_xgb_lag.fit(X, y)\n",
    "\n",
    "# === 2) 取出「前處理」後的特徵名稱 ===\n",
    "# 先經過 lag/rolling 轉換，再問 ColumnTransformer 要欄名\n",
    "X_after_lag = pipe_xgb_lag.named_steps['lagrolls'].transform(X)\n",
    "\n",
    "pre = pipe_xgb_lag.named_steps['pre']\n",
    "# sklearn >= 1.0 支援 get_feature_names_out；若你的版本較舊，見下面備案\n",
    "feature_names = pre.get_feature_names_out(input_features=getattr(X_after_lag, \"columns\", None))\n",
    "\n",
    "# === 3) 從 XGB 取得重要度並對上欄名 ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "xgb_model = pipe_xgb_lag.named_steps['xgb']\n",
    "fi = pd.Series(xgb_model.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "# 看前 30 名\n",
    "top_n = 30\n",
    "print(fi.head(top_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7eb450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB CV mean: 0.9655650285767526\n",
      "XGB CV each split: [0.96885715 0.96439589 0.96714527 0.95672104 0.97070579]\n"
     ]
    }
   ],
   "source": [
    "# 嘗試只保留lag/rolling特徵\n",
    "\n",
    "\n",
    "# === 定義欄位 ===\n",
    "date_col  = \"year_month\"\n",
    "group_col = \"sector\"\n",
    "y_col     = [\"amount_new_house_transactions\"]\n",
    "\n",
    "cat_cols = ['month', 'sector', 'year', 'keyword', 'source']\n",
    "\n",
    "# 數值欄位: 自動選 numeric & 排除掉 y, group, date\n",
    "exclude = set(cat_cols + y_col + [date_col, group_col])\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in exclude]\n",
    "\n",
    "# === Lag 特徵生成器 ===\n",
    "lagrolls = GroupTimeLagRoller(\n",
    "    group_key=group_col,\n",
    "    time_col=date_col,\n",
    "    cols=y_col,\n",
    "    lags=[1, 3, 12],\n",
    "    roll_windows=[3, 6],\n",
    "    roll_funcs=['mean'],\n",
    "    shift_for_rolling=1,\n",
    "    drop_original_y=True,\n",
    "    return_only_new_features=True\n",
    ")\n",
    "\n",
    "lag_cols = lagrolls.get_column_names()\n",
    "\n",
    "# === Column Selector: 排除 lag 用來 impute ===\n",
    "def select_num_excl_lag(X):\n",
    "    numeric = X.select_dtypes(include=[np.number]).columns\n",
    "    return [c for c in numeric if c not in set(lag_cols)]\n",
    "\n",
    "# === ColumnTransformer ===\n",
    "pre_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('lag',SimpleImputer(strategy='constant',fill_value=0),lag_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# === Pipeline ===\n",
    "pipe_xgb_lag = Pipeline([\n",
    "    ('lagrolls', lagrolls),\n",
    "    ('pre', pre_tree),\n",
    "    ('xgb', xgb)   \n",
    "])\n",
    "\n",
    "# === Cross Validation ===\n",
    "X = df\n",
    "y = df[y_col[0]]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "cv_scores_xgb = cross_val_score(pipe_xgb_lag, X=X, y=y, cv=tscv, scoring=kaggle_scorer)\n",
    "\n",
    "print(\"XGB CV mean:\", cv_scores_xgb.mean())\n",
    "print(\"XGB CV each split:\", cv_scores_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d075fe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best score (CV): 0.9688623308934974\n",
      "Best params:\n",
      "  xgb__colsample_bytree: 0.6147547789418131\n",
      "  xgb__gamma: 0.0001849057164788623\n",
      "  xgb__learning_rate: 0.01758720770925141\n",
      "  xgb__max_depth: 8\n",
      "  xgb__min_child_weight: 0.1256470217114413\n",
      "  xgb__n_estimators: 1035\n",
      "  xgb__reg_alpha: 3.477998816092334\n",
      "  xgb__reg_lambda: 0.009083381663660588\n",
      "  xgb__subsample: 0.6579579488364892\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1) 超參數搜尋空間（XGBRegressor in Pipeline -> 'xgb__*'） ---\n",
    "param_dist = {\n",
    "    \"xgb__n_estimators\": randint(300, 1200),\n",
    "    \"xgb__max_depth\": randint(3, 10),\n",
    "    \"xgb__learning_rate\": loguniform(1e-3, 3e-1),\n",
    "    \"xgb__subsample\": uniform(0.6, 0.4),          # 0.6 ~ 1.0\n",
    "    \"xgb__colsample_bytree\": uniform(0.6, 0.4),   # 0.6 ~ 1.0\n",
    "    \"xgb__min_child_weight\": loguniform(1e-1, 1e2),\n",
    "    \"xgb__reg_alpha\": loguniform(1e-4, 1e1),\n",
    "    \"xgb__reg_lambda\": loguniform(1e-3, 1e1),\n",
    "    \"xgb__gamma\": loguniform(1e-8, 1e-1),\n",
    "}\n",
    "\n",
    "# --- 2) 建立 RandomizedSearchCV ---\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=pipe_xgb_lag,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,                \n",
    "    cv=tscv,                  \n",
    "    scoring=kaggle_scorer,    \n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    refit=True,                # 以最佳參數在全資料上重訓\n",
    "    error_score=\"raise\"        # 有錯直接丟出來好除錯\n",
    ")\n",
    "\n",
    "# --- 3) 執行搜尋 ---\n",
    "rs.fit(X, y)\n",
    "\n",
    "print(\"Best score (CV):\", rs.best_score_)\n",
    "print(\"Best params:\")\n",
    "for k, v in rs.best_params_.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# 最佳模型（已用最佳參數 refit 完成）\n",
    "best_model = rs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "672ef1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> models/xgb_lag_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# 1) 取最佳參數，建立最終管線並重訓\n",
    "best_params = rs.best_params_\n",
    "pipe_final = pipe_xgb_lag.set_params(**best_params)\n",
    "\n",
    "# 全資料重訓（與 rs.refit 類似，但我們明確再跑一次）\n",
    "pipe_final.fit(X, y)\n",
    "\n",
    "# 2) 存檔（models/ 目錄）\n",
    "import joblib, os\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(pipe_final, \"models/xgb_lag_pipeline.joblib\", compress=3)\n",
    "\n",
    "print(\"Saved -> models/xgb_lag_pipeline.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b02e2e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn 1.6.1\n",
      "xgboost 3.0.4\n",
      "pandas 2.2.3\n",
      "numpy 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn, xgboost, pandas, numpy\n",
    "print(\"sklearn\", sklearn.__version__)\n",
    "print(\"xgboost\", xgboost.__version__)\n",
    "print(\"pandas\", pandas.__version__)\n",
    "print(\"numpy\", numpy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c43a82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
